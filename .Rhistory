(Minv%*%M)
# Dekompozycja QR macierzy
(QR <- qr(M))
QR$rank
qr.Q(QR) # Wydobycie macierzy Q
qr.R(QR) # Wydobycie macierzy R
qr.X(QR)
print(a)
(f <- round(runif(length(a), -1, 5)))
(raf <- rbind(a, f))
rownames(raf) <- NULL
print(raf)
(caf <- cbind(V1 = a, V2 = f)) # alternatywnie (caf<-cbind(V1=a,V2=f)); colnames(caf)<-c("V1","V2")
(B <- matrix(1:25, ncol = 5))
args(matrix)
B[2, 3]
B[4:5, ]
B[, 2:3]
B[, -(2:3)]
nrow(B)
ncol(B)
dim(B) # Wymiary macierzy B
colMeans(B)
rowMeans(B)
colSums(B)
rowSums(B)
t(B) # Transpozycja macierzy B
det(B) # Wyznacznik macierzy B
#wyznacz wartosc funkcji (tutaj sumy) dla kazdego wiersza macierzy
apply(B, 1, sum)
#wyznaczanie wartosci funkcji (tutaj sumy) dla kazdej kolumny macierzy
apply(B, 2, sum)
# wyznacz wartosc zadanej funkcji dla kazdej kolumny macierzy
apply(B, 2, function (x) mean(x) + 5)
# Tworzenie macierzy z elementami pseudolosowymi
F <- matrix(rnorm(100, 170, 15), ncol = 5)
G <- matrix(rnorm(15, 170, 15), nrow = 5)
H <- matrix(rnorm(100), ncol = 5)#z rozkladu standaryzowanego, wart oczek = 0 , odh std = 1
dim(F)
dim(G)
dim(H)
# Iloczyn macierzy      %*%
(L <- F %*% G)
dim(L)
# Iloczyn Hadamarda      *
(K <- F * H)
dim(K)
# Iloczyn Kroneckera    %x%
(Z <- B %x% G)
dim(Z)
# alternatywnie
kronecker(B, G)
# Iloczyn skalarny      "crossprod"
(dotB <- crossprod(B)) # B'B
dim(dotB)
all.equal(dotB, t(B) %*% B)
(dotFH <- crossprod(F, H)) # F'H
all.equal(dotFH, t(F) %*% H)
# Outer product
(outB <- tcrossprod(B)) # BB'
dim(outB)
(outFH <- tcrossprod(F, H)) # FH'
dim(outFH)
# Macierz kwadratowa stopnia 5 z elementami pseudolosowymi
(M <- (matrix(round(rnorm(25, 10, 2)), ncol = 5)))
dim(M)
det(M)
(Minv <- solve(M))
# Dekompozycja QR macierzy
(QR <- qr(M))
QR$rank
qr.Q(QR) # Wydobycie macierzy Q
qr.R(QR) # Wydobycie macierzy R
qr.X(QR)
install.packages("C:/Users/user/Downloads/SDSFoundations_1.1/SDSFoundations/R/SDSFoundations", repos = NULL)
install.packages("tm")
library("tm", lib.loc="C:/Program Files/R/R-3.5.2/library")
library(tm)
workDir <- "D:\\Textmining_copy"
load(file = "data.RData")
load(file = "~/data.RData")
load(file = "~/.RData")
load(file = "data/data.RData")
View(data)
glm(formula = kredyt~., data=data, family = binomial(link = "logit"))
summary(glm(formula = kredyt~., data=data, family = binomial(link = "logit")))
glm(formula = kredyt~., data=data, family = binomial(link = "logit"))->res
res
predict(res,data[,1:4])
numeric(as.logical(predict(res,data[,1:4])))
predict(res,data[,1:4])->pred
length(pred)
as.numeric(pred>0)
getwd()
load(choose.files(data.RData))
load(choose.files(data/data.RData))
load(choose.files(data.RData))
load(choose.files())
setwd()
?setwd()
getwd()
load(choose.files())
?getwd()
?setwd()
#wЕ‚Д…czenie bibliotek
library(tm)
#zmiana katalogu roboczego
workDir <- "D:\\Польша\\Образование в Польше\\Uniwersytet ekonomiczny\\Studia magisterskie\\Przetwarzanie języka naturalnego\\Textmining_copy"
setwd(workDir)
workDir
setwd("D:/Польша/Образование в Польше/Uniwersytet ekonomiczny/Studia magisterskie/Przetwarzanie języka naturalnego/Textmining_copy")
setwd("D:/Польша/Образование в Польше/Uniwersytet ekonomiczny/Studia magisterskie/Przetwarzanie języka naturalnego/Textmining_copy")
getwd()
#zmiana katalogu roboczego
workDir <- "D:\\Польша\\Образование в Польше\\Uniwersytet ekonomiczny\\Studia magisterskie\\Przetwarzanie języka naturalnego\\Textmining_copy\\workspace"
setwd(workDir)
?matrix
plot(cars)
?rnorm
?runif
v = c(1:3)  # a vector with [1.0 2.0 3.0]
cat(v, "\n\n")
v = vector(mode="integer", 4)  # [0 0 0 0]
cat(v, "\n\n")
v = c("a", "b", "x")
cat(v, "\n\n")
ls = list("a", 2.2)
ls[3] = as.integer(3)
print(ls)
ls = list(name="Smith", age=22)
cat(ls$name, ":", ls$age)
#Array code
arr = array(0.0, 3)  # [0.0 0.0 0.0]
print(arr)
arr = array(0.0, c(2,3))  # 2x3 matrix
print(arr)
arr = array(0.0, c(2,5,4)) # 2x5x4 n-array
print(arr)  # 40 values displayed
X<- matrix(c(4,7,0,1,1,8,6,1,0,0,0,0,4,7,9,1,1,8,8,
5,0,1,9,6,8,2,1,5,6,4,0,9,8,0,6,1,5,4,1,7),
nrow=8,ncol=5,byrow=TRUE)
rownames(x)<-paste("w",1:8,sep="")
colnames(x)<-paste("k",1:5,sep="")
X<- matrix(c(4,7,0,1,1,8,6,1,0,0,0,0,4,7,9,1,1,8,8,
5,0,1,9,6,8,2,1,5,6,4,0,9,8,0,6,1,5,4,1,7),
nrow=8,ncol=5,byrow=TRUE)
rownames(x)<-paste("w",1:8,sep="")
colnames(x)<-paste("k",1:5,sep="")
library("tm", lib.loc="C:/Program Files/R/R-3.6.3/library")
library("hunspell", lib.loc="C:/Program Files/R/R-3.6.3/library")
X<- matrix(c(4,7,0,1,1,8,6,1,0,0,0,0,4,7,9,1,1,8,8,
5,0,1,9,6,8,2,1,5,6,4,0,9,8,0,6,1,5,4,1,7),
nrow=8,ncol=5,byrow=TRUE)
rownames(x)<-paste("w",1:8,sep="")
colnames(x)<-paste("k",1:5,sep="")
# Program 5.3.
# Analiza ukrytych wymiarów semantycznych
library(tm)
library(lsa)
katalog <- "./Artykuly-stem/"
korpus <- VCorpus(DirSource(katalog,encoding="UTF-8"), readerControl = list(reader=readPlain))
korpus <- tm_map(korpus,removeNumbers)
korpus <- tm_map(korpus,stripWhitespace)
korpus <- tm_map(korpus,removePunctuation)
dtm_tfidf<-DocumentTermMatrix(korpus,control=list(weighting=weightTfIdf,bounds = list(global = c(2,9))))
txt.matrix<-as.textmatrix(t(as.matrix(dtm_tfidf)))
# w macierzy txt.matrix:
# wiersze reprezentują wyrazy
# kolumny reprezentują dokumenty
lsa.model<-lsa(txt.matrix)
# lsa.model$tk - odpowiednik macierzy U
# lsa.model$dk - odpowiednik macierzy V
# lsa.model$sk - odpowiednik macierzy D
wsp.wyrazow<-lsa.model$tk%*%diag(lsa.model$sk)
wsp.dokumentow<-lsa.model$dk%*%diag(lsa.model$sk)
slowa<-c("zawał","bramka","zupa","nadciśnienie","dieta","sprężarka")
wsp.slowa<-wsp.wyrazow[slowa,]
plot(c(wsp.slowa[,1],wsp.dokumentow[,1]),c(wsp.slowa[,2],wsp.dokumentow[,2]))
text(c(wsp.slowa[,1],wsp.dokumentow[,1]),c(wsp.slowa[,2],wsp.dokumentow[,2]),c(rownames(wsp.slowa),paste("d",1:15,sep="")),pos=4)
print(rownames(wsp.dokumentow))
# Program 5.3.
# Analiza ukrytych wymiarów semantycznych
library(tm)
library(lsa)
katalog <- "D://Polsk//Edukacja_w_Polsce//Uniwersytet ekonomiczny//Studia magisterskie//Przetwarzanie jezyka naturalnego//Artykuly-stem"
korpus <- VCorpus(DirSource(katalog,encoding="UTF-8"), readerControl = list(reader=readPlain))
korpus <- tm_map(korpus,removeNumbers)
korpus <- tm_map(korpus,stripWhitespace)
korpus <- tm_map(korpus,removePunctuation)
dtm_tfidf<-DocumentTermMatrix(korpus,control=list(weighting=weightTfIdf,bounds = list(global = c(2,9))))
txt.matrix<-as.textmatrix(t(as.matrix(dtm_tfidf)))
# w macierzy txt.matrix:
# wiersze reprezentują wyrazy
# kolumny reprezentują dokumenty
lsa.model<-lsa(txt.matrix)
# lsa.model$tk - odpowiednik macierzy U
# lsa.model$dk - odpowiednik macierzy V
# lsa.model$sk - odpowiednik macierzy D
wsp.wyrazow<-lsa.model$tk%*%diag(lsa.model$sk)
wsp.dokumentow<-lsa.model$dk%*%diag(lsa.model$sk)
slowa<-c("zawał","bramka","zupa","nadciśnienie","dieta","sprężarka")
wsp.slowa<-wsp.wyrazow[slowa,]
plot(c(wsp.slowa[,1],wsp.dokumentow[,1]),c(wsp.slowa[,2],wsp.dokumentow[,2]))
text(c(wsp.slowa[,1],wsp.dokumentow[,1]),c(wsp.slowa[,2],wsp.dokumentow[,2]),c(rownames(wsp.slowa),paste("d",1:15,sep="")),pos=4)
print(rownames(wsp.dokumentow))
# Program 5.2
# Tworzenie przykładowej macierzy X
x<-matrix(c(4,7,0,1,1,8,6,1,0,0,0,0,4,7,9,1,1,8,8,5,0,1,9,6,8,2,1,5,6,4,0,9,8,0,6,1,5,4,1,7),nrow=8,ncol=5,byrow=TRUE)
rownames(x)<-paste("w",1:8,sep="")
colnames(x)<-paste("k",1:5,sep="")
# Program 5.3.
# Analiza ukrytych wymiarów semantycznych
library(tm)
library(lsa)
katalog <- "D://Polsk//Edukacja_w_Polsce//Uniwersytet ekonomiczny//Studia magisterskie//Przetwarzanie jezyka naturalnego//Artykuly-stem"
korpus <- VCorpus(DirSource(katalog,encoding="UTF-8"), readerControl = list(reader=readPlain))
korpus <- tm_map(korpus,removeNumbers)
korpus <- tm_map(korpus,stripWhitespace)
korpus <- tm_map(korpus,removePunctuation)
dtm_tfidf<-DocumentTermMatrix(korpus,control=list(weighting=weightTfIdf,bounds = list(global = c(2,9))))
txt.matrix<-as.textmatrix(t(as.matrix(dtm_tfidf)))
# w macierzy txt.matrix:
# wiersze reprezentują wyrazy
# kolumny reprezentują dokumenty
lsa.model<-lsa(txt.matrix)
# lsa.model$tk - odpowiednik macierzy U
# lsa.model$dk - odpowiednik macierzy V
# lsa.model$sk - odpowiednik macierzy D
wsp.wyrazow<-lsa.model$tk%*%diag(lsa.model$sk)
wsp.dokumentow<-lsa.model$dk%*%diag(lsa.model$sk)
slowa<-c("zawał","bramka","zupa","nadciśnienie","dieta","sprężarka")
wsp.slowa<-wsp.wyrazow[slowa,]
plot(c(wsp.slowa[,1],wsp.dokumentow[,1]),c(wsp.slowa[,2],wsp.dokumentow[,2]))
text(c(wsp.slowa[,1],wsp.dokumentow[,1]),c(wsp.slowa[,2],wsp.dokumentow[,2]),c(rownames(wsp.slowa),paste("d",1:15,sep="")),pos=4)
print(rownames(wsp.dokumentow))
# Program 5.1.
# Analiza głównych składowych korpusu dokumentów
library(tm)
katalog <- "D:\\Polska\\Edukacja_w_Polsce\\Uniwersytet ekonomiczny\\Studia magisterskie\\Przetwarzanie jezyka naturalnego\\Artykuly"
korpus <- VCorpus(DirSource(katalog,encoding="UTF-8"), readerControl = list(reader=readPlain))
korpus <- tm_map(korpus,removeNumbers)
korpus <- tm_map(korpus,stripWhitespace)
korpus <- tm_map(korpus,removePunctuation)
dtm_tf<-DocumentTermMatrix(korpus,control=list(bounds = list(global = c(2,9))))
pca<-prcomp(dtm_tf)
options(scipen=5)
print(pca$x[,1:2])
plot(pca$x[,1],sign(pca$x[,2])*log(abs(pca$x[,2]))^0.8,xlim=c(-25,140))
text(pca$x[,1],sign(pca$x[,2])*log(abs(pca$x[,2]))^0.8,xlim=c(-25,140),1:15,pos=4)
print(rownames(pca$x))
# Program 5.2
# Tworzenie przykładowej macierzy X
x<-matrix(c(4,7,0,1,1,8,6,1,0,0,0,0,4,7,9,1,1,8,8,5,0,1,9,6,8,2,1,5,6,4,0,9,8,0,6,1,5,4,1,7),nrow=8,ncol=5,byrow=TRUE)
rownames(x)<-paste("w",1:8,sep="")
colnames(x)<-paste("k",1:5,sep="")
# Program 5.3.
# Analiza ukrytych wymiarów semantycznych
library(tm)
library(lsa)
katalog <- "D://Polsk//Edukacja_w_Polsce//Uniwersytet ekonomiczny//Studia magisterskie//Przetwarzanie jezyka naturalnego//Artykuly-stem"
korpus <- VCorpus(DirSource(katalog,encoding="UTF-8"), readerControl = list(reader=readPlain))
korpus <- tm_map(korpus,removeNumbers)
korpus <- tm_map(korpus,stripWhitespace)
korpus <- tm_map(korpus,removePunctuation)
dtm_tfidf<-DocumentTermMatrix(korpus,control=list(weighting=weightTfIdf,bounds = list(global = c(2,9))))
txt.matrix<-as.textmatrix(t(as.matrix(dtm_tfidf)))
# w macierzy txt.matrix:
# wiersze reprezentują wyrazy
# kolumny reprezentują dokumenty
lsa.model<-lsa(txt.matrix)
# lsa.model$tk - odpowiednik macierzy U
# lsa.model$dk - odpowiednik macierzy V
# lsa.model$sk - odpowiednik macierzy D
wsp.wyrazow<-lsa.model$tk%*%diag(lsa.model$sk)
wsp.dokumentow<-lsa.model$dk%*%diag(lsa.model$sk)
slowa<-c("zawał","bramka","zupa","nadciśnienie","dieta","sprężarka")
wsp.slowa<-wsp.wyrazow[slowa,]
plot(c(wsp.slowa[,1],wsp.dokumentow[,1]),c(wsp.slowa[,2],wsp.dokumentow[,2]))
text(c(wsp.slowa[,1],wsp.dokumentow[,1]),c(wsp.slowa[,2],wsp.dokumentow[,2]),c(rownames(wsp.slowa),paste("d",1:15,sep="")),pos=4)
print(rownames(wsp.dokumentow))
# Program 5.1.
# Analiza głównych składowych korpusu dokumentów
library(tm)
katalog <- "D:\\Polska\\Edukacja_w_Polsce\\Uniwersytet ekonomiczny\\Studia magisterskie\\Przetwarzanie jezyka naturalnego\\Artykuly-stem"
korpus <- VCorpus(DirSource(katalog,encoding="UTF-8"), readerControl = list(reader=readPlain))
korpus <- tm_map(korpus,removeNumbers)
korpus <- tm_map(korpus,stripWhitespace)
korpus <- tm_map(korpus,removePunctuation)
dtm_tf<-DocumentTermMatrix(korpus,control=list(bounds = list(global = c(2,9))))
pca<-prcomp(dtm_tf)
options(scipen=5)
print(pca$x[,1:2])
plot(pca$x[,1],sign(pca$x[,2])*log(abs(pca$x[,2]))^0.8,xlim=c(-25,140))
text(pca$x[,1],sign(pca$x[,2])*log(abs(pca$x[,2]))^0.8,xlim=c(-25,140),1:15,pos=4)
print(rownames(pca$x))
# Program 5.2
# Tworzenie przykładowej macierzy X
x<-matrix(c(4,7,0,1,1,8,6,1,0,0,0,0,4,7,9,1,1,8,8,5,0,1,9,6,8,2,1,5,6,4,0,9,8,0,6,1,5,4,1,7),nrow=8,ncol=5,byrow=TRUE)
rownames(x)<-paste("w",1:8,sep="")
colnames(x)<-paste("k",1:5,sep="")
# Program 5.3.
# Analiza ukrytych wymiarów semantycznych
library(tm)
library(lsa)
katalog <- "D://Polsk//Edukacja_w_Polsce//Uniwersytet ekonomiczny//Studia magisterskie//Przetwarzanie jezyka naturalnego//Artykuly-stem"
korpus <- VCorpus(DirSource(katalog,encoding="UTF-8"), readerControl = list(reader=readPlain))
korpus <- tm_map(korpus,removeNumbers)
korpus <- tm_map(korpus,stripWhitespace)
korpus <- tm_map(korpus,removePunctuation)
dtm_tfidf<-DocumentTermMatrix(korpus,control=list(weighting=weightTfIdf,bounds = list(global = c(2,9))))
txt.matrix<-as.textmatrix(t(as.matrix(dtm_tfidf)))
# w macierzy txt.matrix:
# wiersze reprezentują wyrazy
# kolumny reprezentują dokumenty
lsa.model<-lsa(txt.matrix)
# lsa.model$tk - odpowiednik macierzy U
# lsa.model$dk - odpowiednik macierzy V
# lsa.model$sk - odpowiednik macierzy D
wsp.wyrazow<-lsa.model$tk%*%diag(lsa.model$sk)
wsp.dokumentow<-lsa.model$dk%*%diag(lsa.model$sk)
slowa<-c("zawał","bramka","zupa","nadciśnienie","dieta","sprężarka")
wsp.slowa<-wsp.wyrazow[slowa,]
plot(c(wsp.slowa[,1],wsp.dokumentow[,1]),c(wsp.slowa[,2],wsp.dokumentow[,2]))
text(c(wsp.slowa[,1],wsp.dokumentow[,1]),c(wsp.slowa[,2],wsp.dokumentow[,2]),c(rownames(wsp.slowa),paste("d",1:15,sep="")),pos=4)
print(rownames(wsp.dokumentow))
# Program 5.1.
# Analiza głównych składowych korpusu dokumentów
library(tm)
katalog <- "D:\\Polska\\Edukacja_w_Polsce\\Uniwersytet ekonomiczny\\Studia magisterskie\\Przetwarzanie jezyka naturalnego\\Artykuly-stem"
korpus <- VCorpus(DirSource(katalog,encoding="UTF-8"), readerControl = list(reader=readPlain))
korpus <- tm_map(korpus,removeNumbers)
korpus <- tm_map(korpus,stripWhitespace)
korpus <- tm_map(korpus,removePunctuation)
dtm_tf<-DocumentTermMatrix(korpus,control=list(bounds = list(global = c(2,9))))
pca<-prcomp(dtm_tf)
options(scipen=5)
print(pca$x[,1:2])
plot(pca$x[,1],sign(pca$x[,2])*log(abs(pca$x[,2]))^0.8,xlim=c(-25,140))
text(pca$x[,1],sign(pca$x[,2])*log(abs(pca$x[,2]))^0.8,xlim=c(-25,140),1:15,pos=4)
print(rownames(pca$x))
# Program 5.2
# Tworzenie przykładowej macierzy X
x<-matrix(c(4,7,0,1,1,8,6,1,0,0,0,0,4,7,9,1,1,8,8,5,0,1,9,6,8,2,1,5,6,4,0,9,8,0,6,1,5,4,1,7),nrow=8,ncol=5,byrow=TRUE)
rownames(x)<-paste("w",1:8,sep="")
colnames(x)<-paste("k",1:5,sep="")
# Program 5.3.
# Analiza ukrytych wymiarów semantycznych
library(tm)
library(lsa)
katalog <- "D://Polska//Edukacja_w_Polsce//Uniwersytet ekonomiczny//Studia magisterskie//Przetwarzanie jezyka naturalnego//Artykuly-stem"
korpus <- VCorpus(DirSource(katalog,encoding="UTF-8"), readerControl = list(reader=readPlain))
korpus <- tm_map(korpus,removeNumbers)
korpus <- tm_map(korpus,stripWhitespace)
korpus <- tm_map(korpus,removePunctuation)
dtm_tfidf<-DocumentTermMatrix(korpus,control=list(weighting=weightTfIdf,bounds = list(global = c(2,9))))
txt.matrix<-as.textmatrix(t(as.matrix(dtm_tfidf)))
# w macierzy txt.matrix:
# wiersze reprezentują wyrazy
# kolumny reprezentują dokumenty
lsa.model<-lsa(txt.matrix)
# lsa.model$tk - odpowiednik macierzy U
# lsa.model$dk - odpowiednik macierzy V
# lsa.model$sk - odpowiednik macierzy D
wsp.wyrazow<-lsa.model$tk%*%diag(lsa.model$sk)
wsp.dokumentow<-lsa.model$dk%*%diag(lsa.model$sk)
slowa<-c("zawał","bramka","zupa","nadciśnienie","dieta","sprężarka")
wsp.slowa<-wsp.wyrazow[slowa,]
plot(c(wsp.slowa[,1],wsp.dokumentow[,1]),c(wsp.slowa[,2],wsp.dokumentow[,2]))
text(c(wsp.slowa[,1],wsp.dokumentow[,1]),c(wsp.slowa[,2],wsp.dokumentow[,2]),c(rownames(wsp.slowa),paste("d",1:15,sep="")),pos=4)
print(rownames(wsp.dokumentow))
str(dtm_tfidf)
str(lsa.model)
slowa
wsp.wyrazow[slowa,]
install.packages("lsa")
# Program 5.3.
# Analiza ukrytych wymiarów semantycznych
library(tm)
library(lsa)
katalog <- "D://Polska//Edukacja_w_Polsce//Uniwersytet ekonomiczny//Studia magisterskie//Przetwarzanie jezyka naturalnego//Artykuly-stem"
korpus <- VCorpus(DirSource(katalog,encoding="UTF-8"), readerControl = list(reader=readPlain))
korpus <- tm_map(korpus,removeNumbers)
korpus <- tm_map(korpus,stripWhitespace)
korpus <- tm_map(korpus,removePunctuation)
dtm_tfidf<-DocumentTermMatrix(korpus,control=list(weighting=weightTfIdf,bounds = list(global = c(2,9))))
txt.matrix<-as.textmatrix(t(as.matrix(dtm_tfidf)))
# w macierzy txt.matrix:
# wiersze reprezentują wyrazy
# kolumny reprezentują dokumenty
lsa.model<-lsa(txt.matrix)
# lsa.model$tk - odpowiednik macierzy U
# lsa.model$dk - odpowiednik macierzy V
# lsa.model$sk - odpowiednik macierzy D
wsp.wyrazow<-lsa.model$tk%*%diag(lsa.model$sk)
wsp.dokumentow<-lsa.model$dk%*%diag(lsa.model$sk)
slowa<-c("bramka","zupa","dieta")
wsp.slowa<-wsp.wyrazow[slowa,]
plot(c(wsp.slowa[,1],wsp.dokumentow[,1]),c(wsp.slowa[,2],wsp.dokumentow[,2]))
text(c(wsp.slowa[,1],wsp.dokumentow[,1]),c(wsp.slowa[,2],wsp.dokumentow[,2]),c(rownames(wsp.slowa),paste("d",1:15,sep="")),pos=4)
print(rownames(wsp.dokumentow))
load("D:/Polska/Edukacja_w_Polsce/Uniwersytet ekonomiczny/Studia magisterskie/Przetwarzanie jezyka naturalnego/Textmining/workspaces/31_03_2020.Rdata")
View(`F`)
wsp.dokumentow<-lsa.model$dk%*%diag(lsa.model$sk)
#włączenie bibliotek
library(tm)
#zmiana katalogu roboczego
workDir <- "D:\\Polska\\Edukacja_w_Polsce\\Uniwersytet ekonomiczny\\Studia magisterskie\\Przetwarzanie jezyka naturalnego\\Textmining"
setwd(workDir)
#definicja katalogów projektu
# . - to jest katalog roboczy, a nie bieżący
inputDir <- ".\\data"
outputDir <- ".\\results"
scriptsDir <- ".\\scripts"
workspaceDir <- ".\\workspaces"
#utworzenie katalogu wyjściowego
dir.create(outputDir, showWarnings = FALSE)
dir.create(workspaceDir, showWarnings = FALSE)
#utworzenie korpusu dokumentów - chcemy do input dir dokleić ścieżkę dostępu, ale ta zmienna zawiera tylko adres
corpusDir <- paste(inputDir, "\\",  "Literatura - streszczenia - przetworzone", sep = "")
#VCorpus - tworzy obiekt korpusu dokumentów
corpus <- VCorpus(
DirSource(
corpusDir,
pattern = "*.txt",
encoding = "UTF-8"
),
readerControl = list(
language = "pl_PL"
)
)
cutExtentions <- function(document){
#chcemy metadaną o id dokumentu podmienić na
meta(document, "id") <- gsub(pattern = "\\.txt$", "", meta(document, "id"))#gsub nie zmienia tekstu podawanego jako parametr,
#dlatego, jeśli chcemy zachować zmianę, to musimy z powrotem przypisać (<-)
return(document)
}
corpus <- tm_map(corpus, cutExtentions)
#utworzenie macierzy częstości
tdmTfAll <- TermDocumentMatrix(corpus)
dtmTfAll <- DocumentTermMatrix(corpus)
tdmTfidfAll <- TermDocumentMatrix(
corpus,
control = list(
weighting = weightBin
)
)
tdmBinAll <- TermDocumentMatrix(
corpus,
control = list(
weighting = weightBin
)
)
tdmTfBounds <- TermDocumentMatrix(
corpus,
control = list(
bounds = list(
global = c(2,16)
)
)
)
tdmTfidfBounds <- TermDocumentMatrix(
corpus,
control = list(
weighting = weightTfIdf,
bounds = list(
global = c(2,16)
)
)
)
#tdm zmienilismy na dtm, zeby nie transponowac tdm do dtm(?bo miacierz zawierala bardzo duzo wymiarow(slow)?)
dtmTfidfBounds <- DocumentTermMatrix(
corpus,
control = list(
weighting = weightTfIdf,
bounds = list(
global = c(2,16)
)
)
)
tdmTfAllMatrix <- as.matrix(tdmTfAll)
dtmTfAllMatrix <- as.matrix(dtmTfAll)
tdmTfidfAllMatrix <- as.matrix(tdmTfidfAll)
tdmBinAllMatrix <- as.matrix(tdmBinAll)
tdmTfBoundsMatrix <- as.matrix(tdmTfBounds)
tdmTfidfBoundsMatrix <- as.matrix(tdmTfidfBounds)
dtmTfidfBoundsMatrix <- as.matrix(dtmTfidfBounds)
#eksport macierzy do pliku .csv
#matrixFile <- paste(
# outputDir,
#"\\",
#"Literatura - streszczenia - przetworzone",
#sep = ""
#)
#write.table(tdmTfidfBoundsMatrix, file = matrixFile, sep = ";", dec = ",", col.names = NA)
save.image("D:/Polska/Edukacja_w_Polsce/Uniwersytet ekonomiczny/Studia magisterskie/Przetwarzanie jezyka naturalnego/Textmining/workspaces/31_03_2020.RData")
scriptsDir <- ".\\scripts"
sourceFile <- paste(
scriptsDir,
"\\",
"script_2.R",
sep = ""
)
source(sourceFile)
#skalowanie wielowymiarowe
d <- dist(dtmTfidfBoundsMatrix)
fit <- cmdscale(d,eig=TRUE, k=2)
x <- fit$points[,1]
y <- fit$points[,2]
plot(x, y, xlab="Coordinate 1", ylab="Coordinate 2",
main="Metric MDS", type="n")
text(x, y, labels = row.names(dtmTfidfBoundsMatrix), cex=.7)
save.image("D:/Polska/Edukacja_w_Polsce/Uniwersytet ekonomiczny/Studia magisterskie/Przetwarzanie jezyka naturalnego/Textmining/workspaces/skalowanie_wielowymiarowe.RData")
