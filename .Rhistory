labels(ftx)
# Uporzadkowane kategorie
war <- c("niski", "sredni", "wysoki")
(stan <- war[floor(runif(100, 1, 4))])
u<-runif(1000,0,1)
set.seed(123)
runif(10)
runif(10)
set.seed(123)
runif(10)
set.seed(124)
runif(10)
hist(u)
u<-runif(10^6,0,1)
hist(u)
x<-qnorm(u,178,3)
hist(x,col="blue")
war <- c("niski", "sredni", "wysoki")
(stan <- war[floor(runif(100, 1, 4))])
(d <- factor(stan, levels = war, ordered = TRUE))
levels(d)
unclass(d)
is.ordered(d)
# Wektory logiczne
(e <- as.logical(a))
a
(vl <- a > 5 & a < 10)
any(vl); all(vl)
!vl
# Tworzenie macierzy liczb
print(a)
(f <- round(runif(length(a), -1, 5)))
set.seed(1)
(f <- round(runif(length(a), -1, 5)))
set.seed(1)
(f <- round(runif(length(a), -1, 5)))
(f <- round(runif(length(a), -1, 5)))
typeof(a)
(raf <- rbind(a, f))
rownames(raf) <- NULL
print(raf)
(caf <- cbind(V1 = a, V2 = f)) # alternatywnie (caf<-cbind(V1=a,V2=f)); colnames(caf)<-c("V1","V2")
args(matrix)
(B <- matrix(1:25, ncol = 5))
(B <- matrix(1:25, ncol = 4))
args(matrix)
B[2, 3]
(B <- matrix(1:25, ncol = 4))
(B <- matrix(1:25, ncol = 5))
B[2, 3]
B[4:5, ]
B[, 2:3]
B[, -(2:3)]
nrow(B)
# Tworzenie macierzy liczb
print(a)
(f <- round(runif(length(a), -1, 5)))
##################################################################################################################
### Wektory ###
# Wektory numeryczne
a <- c(1, 7, 9, 5, 10, 14, rep(0, 3))
print(a)
length(a)
class(a)
rev(a)
sort(a)
sort(a, decreasing = TRUE)
order(a)
a[2:5]
a[-(3:4)]
summary(a)
names(a) <- letters[1:length(a)]
# Liczby zespolone
(z <- 5 + 6i)
class(z)
Conj(z)
Mod(z)
abs(z)
Re(z)
Im(z)
Arg(z)
# Pierwiastki wielomianu
if(!require(polynom)) install.packages("polynom")
library(polynom)
# 1 + 2*x + 3*x^2 + 4*x^3
(wiel <- polynomial(1:4))
solve(wiel)
# Wektory licz zespolonych
(x <- rnorm(5))
(y <- rnorm(5))
# Tworzenie wektora liczb zespolonych
(z1 <- complex(real = x, imaginary = y))
as.complex(x)
plot(z1)
# Wektory tekstowe
as.character(a)
(ba <- LETTERS[a + 1])
(tx <- c("czerwony", "zielony", "niebieski"))
class(tx)
is.character(tx)
paste(tx[1], tx[2], sep = "-")
# Wektory czynnikowe (factor)
# Nieuporzadkowane kategorie
(ftx <- factor(rep(tx, 10), ordered = FALSE))
is.ordered(ftx)
# Uporzadkowane kategorie
war <- c("niski", "sredni", "wysoki")
(stan <- war[floor(runif(100, 1, 4))])
(d <- factor(stan, levels = war, ordered = TRUE))
levels(d)
unclass(d)
is.ordered(d)
# Wektory logiczne
(e <- as.logical(a))
#Operatory logiczne &, |, &&, ||, ==, !=, <, <=, >, >=, any, all
(vl <- a > 5 & a < 10)
any(vl); all(vl)
!vl
###########################################################################################################
### Macierze ###
# Tworzenie macierzy liczb
print(a)
typeof(a)
class(a)
(f <- round(runif(length(a), -1, 5)))
(raf <- rbind(a, f))
rownames(raf) <- NULL
print(raf)
(caf <- cbind(V1 = a, V2 = f)) # alternatywnie (caf<-cbind(V1=a,V2=f)); colnames(caf)<-c("V1","V2")
(B <- matrix(1:25, ncol = 5))
args(matrix)
(f <- round(runif(length(a), -1, 5)))
(f <- round(runif(length(a), -1, 5)))
(f <- round(runif(length(a), -1, 5)))
names(a) <- letters[1:length(a)]
names(a)
print(a)
(caf<-cbind(V1=a,V2=f)); colnames(caf)<-c("V1","V2")
(caf<-cbind(V1=a,V2=f));
(colnames(caf)<-c("V1","V2"))
nrow(B)
ncol(B)
dim(B) # Wymiary macierzy B
colMeans(B)
rowMeans(B)
colSums(B)
rowSums(B)
t(B) # Transpozycja macierzy B
det(B) # Wyznacznik macierzy B
#wyznacz wartosc funkcji (tutaj sumy) dla kazdego wiersza macierzy
apply(B, 1, sum)
colMeans(B)
rowMeans(B)
colSums(B)
rowSums(B)
t(B) # Transpozycja macierzy B
det(B) # Wyznacznik macierzy B
#wyznacz wartosc funkcji (tutaj sumy) dla kazdego wiersza macierzy
apply(B, 1, sum)
#wyznaczanie wartosci funkcji (tutaj sumy) dla kazdej kolumny macierzy
apply(B, 2, sum)
# wyznacz wartosc zadanej funkcji dla kazdej kolumny macierzy
apply(B, 2, function (x) mean(x) + 5)
# Tworzenie macierzy z elementami pseudolosowymi
F <- matrix(rnorm(100, 170, 15), ncol = 5)
G <- matrix(rnorm(15, 170, 15), nrow = 5)
H <- matrix(rnorm(100), ncol = 5)
dim(F)
dim(G)
dim(H)
# Iloczyn macierzy      %*%
(L <- F %*% G)
dim(L)
# Iloczyn Hadamarda      *
(K <- F * H)
dim(K)
# Iloczyn Kroneckera    %x%
(Z <- B %x% G)
# Iloczyn skalarny      "crossprod"
(dotB <- crossprod(B)) # B'B
# alternatywnie
kronecker(B, G)
# Iloczyn skalarny      "crossprod"
(dotB <- crossprod(B)) # B'B
# Tworzenie macierzy liczb
print(a)
(f <- round(runif(length(a), -1, 5)))
# Tworzenie macierzy z elementami pseudolosowymi
F <- matrix(rnorm(100, 170, 15), ncol = 5)
G <- matrix(rnorm(15, 170, 15), nrow = 5)
H <- matrix(rnorm(100), ncol = 5)#z rozkladu standaryzowanego, wart oczek = 0 , odh std = 1
dim(F)
dim(G)
dim(H)
# Iloczyn macierzy      %*%
(L <- F %*% G)
dim(L)
# Iloczyn Hadamarda      *
(K <- F * H)
dim(K)
# Iloczyn Kroneckera    %x%
(Z <- B %x% G)
dim(Z)
# alternatywnie
kronecker(B, G)
# Iloczyn skalarny      "crossprod"
(dotB <- crossprod(B)) # B'B
dim(dotB)
all.equal(dotB, t(B) %*% B)
(dotFH <- crossprod(F, H)) # F'H
all.equal(dotFH, t(F) %*% H)
# Outer product
(outB <- tcrossprod(B)) # BB'
dim(outB)
(outFH <- tcrossprod(F, H)) # FH'
dim(outFH)
# Macierz kwadratowa stopnia 5 z elementami pseudolosowymi
(M <- (matrix(round(rnorm(25, 10, 2)), ncol = 5)))
dim(M)
det(M)
(Minv <- solve(M))
# Dekompozycja QR macierzy
(QR <- qr(M))
QR$rank
qr.Q(QR) # Wydobycie macierzy Q
qr.R(QR) # Wydobycie macierzy R
qr.X(QR)
(MInv%*%M)
(Minv%*%M)
# Dekompozycja QR macierzy
(QR <- qr(M))
QR$rank
qr.Q(QR) # Wydobycie macierzy Q
qr.R(QR) # Wydobycie macierzy R
qr.X(QR)
print(a)
(f <- round(runif(length(a), -1, 5)))
(raf <- rbind(a, f))
rownames(raf) <- NULL
print(raf)
(caf <- cbind(V1 = a, V2 = f)) # alternatywnie (caf<-cbind(V1=a,V2=f)); colnames(caf)<-c("V1","V2")
(B <- matrix(1:25, ncol = 5))
args(matrix)
B[2, 3]
B[4:5, ]
B[, 2:3]
B[, -(2:3)]
nrow(B)
ncol(B)
dim(B) # Wymiary macierzy B
colMeans(B)
rowMeans(B)
colSums(B)
rowSums(B)
t(B) # Transpozycja macierzy B
det(B) # Wyznacznik macierzy B
#wyznacz wartosc funkcji (tutaj sumy) dla kazdego wiersza macierzy
apply(B, 1, sum)
#wyznaczanie wartosci funkcji (tutaj sumy) dla kazdej kolumny macierzy
apply(B, 2, sum)
# wyznacz wartosc zadanej funkcji dla kazdej kolumny macierzy
apply(B, 2, function (x) mean(x) + 5)
# Tworzenie macierzy z elementami pseudolosowymi
F <- matrix(rnorm(100, 170, 15), ncol = 5)
G <- matrix(rnorm(15, 170, 15), nrow = 5)
H <- matrix(rnorm(100), ncol = 5)#z rozkladu standaryzowanego, wart oczek = 0 , odh std = 1
dim(F)
dim(G)
dim(H)
# Iloczyn macierzy      %*%
(L <- F %*% G)
dim(L)
# Iloczyn Hadamarda      *
(K <- F * H)
dim(K)
# Iloczyn Kroneckera    %x%
(Z <- B %x% G)
dim(Z)
# alternatywnie
kronecker(B, G)
# Iloczyn skalarny      "crossprod"
(dotB <- crossprod(B)) # B'B
dim(dotB)
all.equal(dotB, t(B) %*% B)
(dotFH <- crossprod(F, H)) # F'H
all.equal(dotFH, t(F) %*% H)
# Outer product
(outB <- tcrossprod(B)) # BB'
dim(outB)
(outFH <- tcrossprod(F, H)) # FH'
dim(outFH)
# Macierz kwadratowa stopnia 5 z elementami pseudolosowymi
(M <- (matrix(round(rnorm(25, 10, 2)), ncol = 5)))
dim(M)
det(M)
(Minv <- solve(M))
# Dekompozycja QR macierzy
(QR <- qr(M))
QR$rank
qr.Q(QR) # Wydobycie macierzy Q
qr.R(QR) # Wydobycie macierzy R
qr.X(QR)
install.packages("C:/Users/user/Downloads/SDSFoundations_1.1/SDSFoundations/R/SDSFoundations", repos = NULL)
install.packages("tm")
library("tm", lib.loc="C:/Program Files/R/R-3.5.2/library")
library(tm)
workDir <- "D:\\Textmining_copy"
load(file = "data.RData")
load(file = "~/data.RData")
load(file = "~/.RData")
load(file = "data/data.RData")
View(data)
glm(formula = kredyt~., data=data, family = binomial(link = "logit"))
summary(glm(formula = kredyt~., data=data, family = binomial(link = "logit")))
glm(formula = kredyt~., data=data, family = binomial(link = "logit"))->res
res
predict(res,data[,1:4])
numeric(as.logical(predict(res,data[,1:4])))
predict(res,data[,1:4])->pred
length(pred)
as.numeric(pred>0)
getwd()
load(choose.files(data.RData))
load(choose.files(data/data.RData))
load(choose.files(data.RData))
load(choose.files())
setwd()
?setwd()
getwd()
load(choose.files())
?getwd()
?setwd()
#wЕ‚Д…czenie bibliotek
library(tm)
#zmiana katalogu roboczego
workDir <- "D:\\Польша\\Образование в Польше\\Uniwersytet ekonomiczny\\Studia magisterskie\\Przetwarzanie języka naturalnego\\Textmining_copy"
setwd(workDir)
workDir
setwd("D:/Польша/Образование в Польше/Uniwersytet ekonomiczny/Studia magisterskie/Przetwarzanie języka naturalnego/Textmining_copy")
setwd("D:/Польша/Образование в Польше/Uniwersytet ekonomiczny/Studia magisterskie/Przetwarzanie języka naturalnego/Textmining_copy")
getwd()
#zmiana katalogu roboczego
workDir <- "D:\\Польша\\Образование в Польше\\Uniwersytet ekonomiczny\\Studia magisterskie\\Przetwarzanie języka naturalnego\\Textmining_copy\\workspace"
setwd(workDir)
getReaders()
getwd
getwd()
library("tm", lib.loc="C:/Program Files/R/R-3.6.3/library")
getwd()
getReaders()
#włączenie bibliotek
library(tm)
#zmiana katalogu roboczego
workDir <- "D:\\Polska\\Edukacja_w_Polsce\\Uniwersytet ekonomiczny\\Studia magisterskie\\Przetwarzanie jezyka naturalnego\\Textmining_copy"
setwd(workDir)
#definicja katalogów projektu
# . - to jest katalog roboczy, a nie bieżący
inputDir <- ".\\data"
outputDir <- ".\\results"
scriptDir <- ".\\scripts"
workspaceDir <- ".\\workspaces"
#utworzy katalog
dir.create(outputDir, showWarnings = FALSE)
#utworzenie korpusu dokumentów - chcemy do input dir dokleić ścieżkę dostępu, ale ta zmienna zawiera tylko adres
corpusDir <- paste(inputDir, "\\",  "Literatura - streszczenia - oryginal", sep = "")
#VCorpus - tworzy obiekt korpusu dokumentów
corpus <- VCorpus(
DirSource(
corpusDir,
pattern = "*.txt",
encoding = "UTF-8"
),
readerControl = list(
language = "pl_PL"
)
)
View(corpus)
# wstepne przetwarzanie
corpus <- tm_map(corpus, removeNumbers) # wykonuje na korpusie daną transformację
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower)) # tolower może działać i na zawartości i na metadanych, jednak my nie chcemy, żeby np. nazwa pliku była sprowadzona do małych liter
# definicja lokalizacji zawierającej stoplistę          # my chcemy tylko zawartość dokumentu sprowadzić do małych liter
stoplistFile <- paste(
inputDir,                                            # funkcja paste zwraca string
"\\",
"stopwords_pl.txt",
sep = "")
stoplist <- readLines(# wczytuje po kolei linijki z pliku do listy(nie do ciągłego tekstu)
stoplistFile,
encoding = "UTF-8"
)
corpus <- tm_map(corpus, removeWords, stoplist)
corpus <- tm_map(corpus, stripWhitespace) # stripWhitespace jest na końcu, bo mogą zostać nadmiarowe "białe znaki"
# bo funkcja removeWords zamienia usuwane przez siebie znaki na spacje
setwd("D:/Polska/Edukacja_w_Polsce/Uniwersytet ekonomiczny/Studia magisterskie/Przetwarzanie jezyka naturalnego/Textmining")
#włączenie bibliotek
library(tm)
#zmiana katalogu roboczego
workDir <- "D:\\Polska\\Edukacja_w_Polsce\\Uniwersytet ekonomiczny\\Studia magisterskie\\Przetwarzanie jezyka naturalnego\\Textmining_copy"
setwd(workDir)
#definicja katalogów projektu
# . - to jest katalog roboczy, a nie bieżący
inputDir <- ".\\data"
outputDir <- ".\\results"
scriptDir <- ".\\scripts"
workspaceDir <- ".\\workspaces"
#utworzy katalog
dir.create(outputDir, showWarnings = FALSE)
#utworzenie korpusu dokumentów - chcemy do input dir dokleić ścieżkę dostępu, ale ta zmienna zawiera tylko adres
corpusDir <- paste(inputDir, "\\",  "Literatura - streszczenia - oryginal", sep = "")
#VCorpus - tworzy obiekt korpusu dokumentów
corpus <- VCorpus(
DirSource(
corpusDir,
pattern = "*.txt",
encoding = "UTF-8"
),
readerControl = list(
language = "pl_PL"
)
)
View(corpus)
# wstepne przetwarzanie
corpus <- tm_map(corpus, removeNumbers) # wykonuje na korpusie daną transformację
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower)) # tolower może działać i na zawartości i na metadanych, jednak my nie chcemy, żeby np. nazwa pliku była sprowadzona do małych liter
# definicja lokalizacji zawierającej stoplistę          # my chcemy tylko zawartość dokumentu sprowadzić do małych liter
stoplistFile <- paste(
inputDir,                                            # funkcja paste zwraca string
"\\",
"stopwords_pl.txt",
sep = "")
stoplist <- readLines(# wczytuje po kolei linijki z pliku do listy(nie do ciągłego tekstu)
stoplistFile,
encoding = "UTF-8"
)
corpus <- tm_map(corpus, removeWords, stoplist)
corpus <- tm_map(corpus, stripWhitespace) # stripWhitespace jest na końcu, bo mogą zostać nadmiarowe "białe znaki"
# bo funkcja removeWords zamienia usuwane przez siebie znaki na spacje
getwd()
setwd("D:/Polska/Edukacja_w_Polsce/Uniwersytet ekonomiczny/Studia magisterskie/Przetwarzanie jezyka naturalnego/Textmining/workspace")
getwd()
setwd("D:/Polska/Edukacja_w_Polsce/Uniwersytet ekonomiczny/Studia magisterskie/Przetwarzanie jezyka naturalnego/Textmining")
install.packages("hunspell")
library("hunspell", lib.loc="C:/Program Files/R/R-3.6.3/library")
library(hunspell)
library (stringr)
install.packages("stringr")
library (stringr)
library (stringr)
library(hunspell)
remove_char <- content_transformer(
function(x, pattern, replacement)
gsub(pattern, replacement, x)
)
#usunięcie "em dash" i 3/4 z tekstów
corpus <- tm_map(corpus, remove_char, intToUtf8(8722), "")
corpus <- tm_map(corpus, remove_char, intToUtf8(190), "")
#lematyzacja - sprowadzenie do formy
polish <- dictionary(lang = "pl_PL")
lemmatize <- function(text){
simple_text <- str_trim(as.character(text[1]))
parsed_text <- strsplit(simple_text, spit = " ")
new_text_vec <- hunspell_stem(parsed_text[[1]], dict = polish)
for (i in 1:length(new_text_vec)){
if(length(new_text_vec[[i]]) == 0) new_text_vec[i] <- parsed_text[[1]][i]
if(length(new_text_vec[[i]]) > 1) new_text_vec[i] <- new_text_vec[[i]][1]
}
new_text <- paste(new_text_vec, collapse = " ")
return(new_text)
}
corpus <- tm_map(corpus, content_transformer(lemmatize))
#lematyzacja - sprowadzenie do formy
polish <- dictionary(lang = "pl_PL")
remove_char <- content_transformer(
function(x, pattern, replacement)
gsub(pattern, replacement, x)
)
#usunięcie "em dash" i 3/4 z tekstów
corpus <- tm_map(corpus, remove_char, intToUtf8(8722), "")
corpus <- tm_map(corpus, remove_char, intToUtf8(190), "")
#lematyzacja - sprowadzenie do formy
polish <- dictionary(lang = "pl_PL")
lemmatize <- function(text){
simple_text <- str_trim(as.character(text[1]))
parsed_text <- strsplit(simple_text, split = " ")
new_text_vec <- hunspell_stem(parsed_text[[1]], dict = polish)
for (i in 1:length(new_text_vec)){
if(length(new_text_vec[[i]]) == 0) new_text_vec[i] <- parsed_text[[1]][i]
if(length(new_text_vec[[i]]) > 1) new_text_vec[i] <- new_text_vec[[i]][1]
}
new_text <- paste(new_text_vec, collapse = " ")
return(new_text)
}
corpus <- tm_map(corpus, content_transformer(lemmatize))
writeLines(as.character(corpus[[1]]))
#bedziemy siegac metadanych w pliku
cut_extentions <- function(document){
meta(document, "id") <- gsub(pattern = "\\.txt$", "", meta(document, "id"))
return(document)
}
corpus <- tm_map(corpus, cut_extentions)
writeLines(as.character(corpus[[1]]))
preprocessed_dir <- paste(
outputDir,
"\\",
"Literatura - streszczenia - przetworzone",
sep = ""
)
dir.create(preprocessed_dir, showWarnings = FALSE)
writeLines(as.character(corpus[[1]]))
writeCorpus(corpus, path = preprocessed_dir)
